"""
Report Generator Service

Generates formatted daily digest reports for Telegram delivery.
Uses a premium text format without emojis.
Supports multiple languages based on user profile.

Reference: Plan specification for report format
"""
import html
import logging
from datetime import datetime
from typing import List, Dict, Any, Optional

from services.content_filter import categorize_filtered_content, get_ai_summary, translate_text, translate_content, _extract_user_language
from utils.json_storage import get_user_profile
from config import MAX_DIGEST_ITEMS

# Separator characters for visual hierarchy
DIVIDER_HEAVY = 'â”'
DIVIDER_LIGHT = 'â”€'
SEPARATOR_LENGTH = 28

logger = logging.getLogger(__name__)


# Localized strings - extensible for any language
LOCALE_STRINGS = {
    "zh": {
        "title": "Web3 æ¯æ—¥ç®€æŠ¥",
        "must_read": "ä»Šæ—¥å¿…çœ‹",
        "recommended": "æ¨è",
        "stats": "ç»Ÿè®¡",
        "sources": "ä¿¡æ¯æº",
        "scanned": "æ‰«ææ¡æ•°",
        "selected": "ç²¾é€‰æ¡æ•°",
        "time_saved": "èŠ‚çœæ—¶é—´",
        "helpful_prompt": "è¿™ä»½ç®€æŠ¥æœ‰å¸®åŠ©å—ï¼Ÿ",
        "no_content": "ä»Šå¤©æ²¡æœ‰ç¬¦åˆä½ åå¥½çš„æ›´æ–°ã€‚",
        "possible_reasons": "å¯èƒ½åŸå› ï¼š",
        "reason_1": "ä¿¡æ¯æºæš‚æ—¶ä¸å¯ç”¨",
        "reason_2": "å†…å®¹ç›¸å…³åº¦ä¸å¤Ÿ",
        "reason_3": "åå¥½è®¾ç½®è¾ƒä¸ºå…·ä½“",
        "check_tomorrow": "æ˜å¤©å†çœ‹çœ‹ã€‚",
        "tip": "æç¤ºï¼šä½¿ç”¨ /settings è°ƒæ•´åå¥½ã€‚",
        "sample_preview": "ç¤ºä¾‹é¢„è§ˆ",
        "preview_desc": "ä»¥ä¸‹æ˜¯ä½ æ¯æ—¥ç®€æŠ¥çš„æ ·å¼é¢„è§ˆã€‚",
        "preview_footer": "ä½ çš„çœŸå®ç®€æŠ¥å°†äºæ˜å¤© 9:00 æ¨é€ã€‚",
        # New strings for item display
        "reason_prefix": "ğŸ’¡ ",
        "source_prefix": "æ¥æº: ",
        "btn_like": "ğŸ‘",
        "btn_not_interested": "ä¸æ„Ÿå…´è¶£",
    },
    "en": {
        "title": "Web3 Daily Digest",
        "must_read": "MUST READ",
        "recommended": "Recommended",
        "stats": "Stats",
        "sources": "Sources",
        "scanned": "Scanned",
        "selected": "Selected",
        "time_saved": "Time saved",
        "helpful_prompt": "Was this helpful?",
        "no_content": "No updates matching your preferences today.",
        "possible_reasons": "Possible reasons:",
        "reason_1": "Sources temporarily unavailable",
        "reason_2": "Content below relevance threshold",
        "reason_3": "Very specific preferences",
        "check_tomorrow": "Check back tomorrow.",
        "tip": "Tip: Use /settings to adjust preferences.",
        "sample_preview": "SAMPLE PREVIEW",
        "preview_desc": "This is how your daily digest will look.",
        "preview_footer": "Your real digest arrives tomorrow at 9:00 AM.",
        # New strings for item display
        "reason_prefix": "ğŸ’¡ ",
        "source_prefix": "Source: ",
        "btn_like": "ğŸ‘",
        "btn_not_interested": "Not interested",
    },
    "ja": {
        "title": "Web3 ãƒ‡ã‚¤ãƒªãƒ¼ãƒ€ã‚¤ã‚¸ã‚§ã‚¹ãƒˆ",
        "must_read": "ä»Šæ—¥ã®å¿…èª­",
        "recommended": "ãŠã™ã™ã‚",
        "stats": "çµ±è¨ˆ",
        "sources": "ã‚½ãƒ¼ã‚¹",
        "scanned": "ã‚¹ã‚­ãƒ£ãƒ³",
        "selected": "é¸æŠ",
        "time_saved": "ç¯€ç´„æ™‚é–“",
        "helpful_prompt": "ã“ã®ãƒ€ã‚¤ã‚¸ã‚§ã‚¹ãƒˆã¯å½¹ã«ç«‹ã¡ã¾ã—ãŸã‹ï¼Ÿ",
        "no_content": "ä»Šæ—¥ã¯ãŠå¥½ã¿ã«åˆã†æ›´æ–°ãŒã‚ã‚Šã¾ã›ã‚“ã€‚",
        "possible_reasons": "è€ƒãˆã‚‰ã‚Œã‚‹ç†ç”±ï¼š",
        "reason_1": "ã‚½ãƒ¼ã‚¹ãŒä¸€æ™‚çš„ã«åˆ©ç”¨ä¸å¯",
        "reason_2": "é–¢é€£æ€§ãŒä½ã„ã‚³ãƒ³ãƒ†ãƒ³ãƒ„",
        "reason_3": "éå¸¸ã«å…·ä½“çš„ãªè¨­å®š",
        "check_tomorrow": "æ˜æ—¥ã¾ãŸç¢ºèªã—ã¦ãã ã•ã„ã€‚",
        "tip": "ãƒ’ãƒ³ãƒˆï¼š/settings ã§è¨­å®šã‚’èª¿æ•´ã§ãã¾ã™ã€‚",
        "sample_preview": "ã‚µãƒ³ãƒ—ãƒ«ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼",
        "preview_desc": "ã“ã‚ŒãŒãƒ‡ã‚¤ãƒªãƒ¼ãƒ€ã‚¤ã‚¸ã‚§ã‚¹ãƒˆã®è¡¨ç¤ºä¾‹ã§ã™ã€‚",
        "preview_footer": "å®Ÿéš›ã®ãƒ€ã‚¤ã‚¸ã‚§ã‚¹ãƒˆã¯æ˜æ—¥9:00ã«å±Šãã¾ã™ã€‚",
        # New strings for item display
        "reason_prefix": "ğŸ’¡ ",
        "source_prefix": "ã‚½ãƒ¼ã‚¹: ",
        "btn_like": "ğŸ‘",
        "btn_not_interested": "èˆˆå‘³ãªã—",
    },
    "ko": {
        "title": "Web3 ë°ì¼ë¦¬ ë‹¤ì´ì œìŠ¤íŠ¸",
        "must_read": "í•„ë…",
        "recommended": "ì¶”ì²œ",
        "stats": "í†µê³„",
        "sources": "ì†ŒìŠ¤",
        "scanned": "ìŠ¤ìº”",
        "selected": "ì„ íƒ",
        "time_saved": "ì ˆì•½ ì‹œê°„",
        "helpful_prompt": "ì´ ë‹¤ì´ì œìŠ¤íŠ¸ê°€ ë„ì›€ì´ ë˜ì—ˆë‚˜ìš”?",
        "no_content": "ì˜¤ëŠ˜ì€ ë§ì¶¤ ì—…ë°ì´íŠ¸ê°€ ì—†ìŠµë‹ˆë‹¤.",
        "possible_reasons": "ê°€ëŠ¥í•œ ì´ìœ :",
        "reason_1": "ì†ŒìŠ¤ë¥¼ ì¼ì‹œì ìœ¼ë¡œ ì‚¬ìš©í•  ìˆ˜ ì—†ìŒ",
        "reason_2": "ê´€ë ¨ì„±ì´ ë‚®ì€ ì½˜í…ì¸ ",
        "reason_3": "ë§¤ìš° êµ¬ì²´ì ì¸ ì„¤ì •",
        "check_tomorrow": "ë‚´ì¼ ë‹¤ì‹œ í™•ì¸í•˜ì„¸ìš”.",
        "tip": "íŒ: /settingsë¡œ ì„¤ì •ì„ ì¡°ì •í•˜ì„¸ìš”.",
        "sample_preview": "ìƒ˜í”Œ ë¯¸ë¦¬ë³´ê¸°",
        "preview_desc": "ë°ì¼ë¦¬ ë‹¤ì´ì œìŠ¤íŠ¸ëŠ” ì´ë ‡ê²Œ ë³´ì…ë‹ˆë‹¤.",
        "preview_footer": "ì‹¤ì œ ë‹¤ì´ì œìŠ¤íŠ¸ëŠ” ë‚´ì¼ ì˜¤ì „ 9ì‹œì— ë„ì°©í•©ë‹ˆë‹¤.",
        # New strings for item display
        "reason_prefix": "ğŸ’¡ ",
        "source_prefix": "ì¶œì²˜: ",
        "btn_like": "ğŸ‘",
        "btn_not_interested": "ê´€ì‹¬ì—†ìŒ",
    },
}


# Language code to full name mapping (for translation API)
LANG_CODE_TO_NAME = {
    "zh": "Chinese",
    "en": "English",
    "ja": "Japanese",
    "ko": "Korean",
    "ru": "Russian",
    "es": "Spanish",
    "fr": "French",
    "de": "German",
    "pt": "Portuguese",
    "ar": "Arabic",
    "vi": "Vietnamese",
    "th": "Thai",
}


def get_translation_language(lang_code: str) -> str:
    """Convert language code to full language name for translation API."""
    return LANG_CODE_TO_NAME.get(lang_code, "Chinese")


# Category display names per language
CATEGORY_NAMES = {
    "zh": {
        "must_read": "ä»Šæ—¥å¿…çœ‹",
        "macro_insights": "è¡Œä¸šå¤§å±€",
        "recommended": "æ¨è",
        "other": "å…¶ä»–",
    },
    "en": {
        "must_read": "MUST READ",
        "macro_insights": "Industry Context",
        "recommended": "Recommended",
        "other": "Other",
    },
    "ja": {
        "must_read": "ä»Šæ—¥ã®å¿…èª­",
        "macro_insights": "æ¥­ç•Œæ¦‚æ³",
        "recommended": "ãŠã™ã™ã‚",
        "other": "ãã®ä»–",
    },
    "ko": {
        "must_read": "í•„ë…",
        "macro_insights": "ì—…ê³„ ë™í–¥",
        "recommended": "ì¶”ì²œ",
        "other": "ê¸°íƒ€",
    },
}


# Language detection patterns
LANGUAGE_MARKERS = {
    "zh": ["ä¸­æ–‡", "ç®€ä½“", "ç¹é«”", "chinese"],
    "en": ["english", "è‹±æ–‡", "è‹±è¯­"],
    "ja": ["æ—¥æœ¬èª", "japanese", "æ—¥è¯­"],
    "ko": ["í•œêµ­ì–´", "korean", "éŸ©è¯­", "éŸ“èª"],
    "ru": ["Ñ€ÑƒÑÑĞºĞ¸Ğ¹", "russian", "ä¿„è¯­"],
    "es": ["espaÃ±ol", "spanish", "è¥¿ç­ç‰™è¯­"],
    "fr": ["franÃ§ais", "french", "æ³•è¯­"],
    "de": ["deutsch", "german", "å¾·è¯­"],
    "pt": ["portuguÃªs", "portuguese", "è‘¡è„ç‰™è¯­"],
    "ar": ["Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©", "arabic", "é˜¿æ‹‰ä¼¯è¯­"],
    "vi": ["tiáº¿ng viá»‡t", "vietnamese", "è¶Šå—è¯­"],
    "th": ["à¹„à¸—à¸¢", "thai", "æ³°è¯­"],
}


def detect_user_language(profile: str) -> str:
    """
    Detect user's preferred language from profile.
    Returns language code (zh, en, ja, ko, etc.) or 'zh' as default.
    """
    if not profile:
        return "zh"  # Default to Chinese

    profile_lower = profile.lower()

    # Check for explicit language markers
    for lang_code, markers in LANGUAGE_MARKERS.items():
        for marker in markers:
            if marker.lower() in profile_lower:
                return lang_code

    # Check for language field pattern like "[ç”¨æˆ·è¯­è¨€] xxx" or "[User Language] xxx"
    import re
    lang_pattern = r'\[(?:ç”¨æˆ·è¯­è¨€|user language)\]\s*[:\-]?\s*(\w+)'
    match = re.search(lang_pattern, profile_lower)
    if match:
        detected = match.group(1).lower()
        # Map common names to codes
        name_to_code = {
            "chinese": "zh", "ä¸­æ–‡": "zh", "ç®€ä½“ä¸­æ–‡": "zh",
            "english": "en", "è‹±æ–‡": "en",
            "japanese": "ja", "æ—¥æœ¬èª": "ja", "æ—¥è¯­": "ja",
            "korean": "ko", "í•œêµ­ì–´": "ko", "éŸ©è¯­": "ko",
            "russian": "ru", "Ñ€ÑƒÑÑĞºĞ¸Ğ¹": "ru",
            "spanish": "es", "espaÃ±ol": "es",
            "french": "fr", "franÃ§ais": "fr",
            "german": "de", "deutsch": "de",
        }
        if detected in name_to_code:
            return name_to_code[detected]

    # Detect by character ranges
    for char in profile:
        # Chinese characters
        if '\u4e00' <= char <= '\u9fff':
            return "zh"
        # Japanese Hiragana/Katakana
        if '\u3040' <= char <= '\u30ff':
            return "ja"
        # Korean Hangul
        if '\uac00' <= char <= '\ud7af' or '\u1100' <= char <= '\u11ff':
            return "ko"
        # Cyrillic (Russian, etc.)
        if '\u0400' <= char <= '\u04ff':
            return "ru"
        # Arabic
        if '\u0600' <= char <= '\u06ff':
            return "ar"
        # Thai
        if '\u0e00' <= char <= '\u0e7f':
            return "th"

    return "zh"  # Default to Chinese


def get_locale(lang: str) -> dict:
    """Get locale strings for a language, with English fallback for unsupported languages."""
    if lang in LOCALE_STRINGS:
        return LOCALE_STRINGS[lang]
    # For unsupported languages, use English as fallback
    return LOCALE_STRINGS["en"]


def get_category_names(lang: str) -> dict:
    """Get category names for a language, with English fallback."""
    if lang in CATEGORY_NAMES:
        return CATEGORY_NAMES[lang]
    return CATEGORY_NAMES["en"]


def format_top_stories(items: List[Dict[str, Any]], lang: str = "zh") -> str:
    """Format top stories section with clear visual hierarchy."""
    if not items:
        return ""

    locale = get_locale(lang)

    lines = [
        locale["top_stories"],
        ""
    ]

    for i, item in enumerate(items[:3], 1):
        title = item.get("title", "Untitled")[:75]
        summary = item.get("summary", "")[:140]
        source = item.get("source", "Unknown")
        link = item.get("link", "")

        lines.append(f"{i}. {title}")
        if summary:
            lines.append(f"   {summary}")
        if link:
            # HTML format: <a href="url">text</a>
            lines.append(f'   <a href="{link}">{source}</a>')
        else:
            lines.append(f"   [{source}]")
        lines.append("")

    return "\n".join(lines)


def format_category_section(category: str, items: List[Dict[str, Any]], lang: str = "zh", max_items: int = None) -> str:
    """Format a category section with compact layout.
    
    Args:
        category: Category name
        items: List of items in this category
        lang: Language for display
        max_items: Max items to display (None = show all)
    """
    if not items:
        return ""

    category_names = get_category_names(lang)
    display_name = category_names.get(category, category.title())
    
    # Apply max_items limit if specified
    display_items = items[:max_items] if max_items else items
    
    lines = [
        f"{display_name} ({len(display_items)})",
        ""
    ]

    for item in display_items:
        title = item.get("title", "Untitled")[:55]
        source = item.get("source", "")
        link = item.get("link", "")

        if link:
            # HTML format for clickable source link
            lines.append(f'  â€¢ {title} <a href="{link}">{source}</a>')
        elif source:
            lines.append(f"  â€¢ {title} [{source}]")
        else:
            lines.append(f"  â€¢ {title}")

    lines.append("")
    return "\n".join(lines)


def format_metrics_section(
    sources_count: int,
    raw_count: int,
    selected_count: int,
    lang: str = "zh"
) -> str:
    """Format the metrics/statistics section with aligned layout."""
    locale = get_locale(lang)
    filter_rate = f"{(selected_count / raw_count * 100):.0f}%" if raw_count > 0 else "N/A"
    time_saved = max(1, raw_count // 30)  # Rough estimate: 2 min per item

    return f"""{locale["stats"]}
  {locale["sources"]}      {sources_count}
  {locale["scanned"]}      {raw_count}
  {locale["selected"]}     {selected_count} ({filter_rate})
  {locale["time_saved"]}   ~{time_saved}h
"""


async def generate_daily_report(
    telegram_id: str,
    filtered_items: List[Dict[str, Any]],
    raw_count: int,
    sources_count: int
) -> str:
    """
    Generate the complete daily digest report.

    Args:
        telegram_id: User's Telegram ID
        filtered_items: List of AI-filtered content items
        raw_count: Total number of raw items scanned
        sources_count: Number of sources monitored

    Returns:
        Formatted report string for Telegram
    """
    date_str = datetime.now().strftime("%Y-%m-%d")

    # Get user profile for AI summary and language detection
    profile = get_user_profile(telegram_id) or "General Web3 interest"

    # Detect user language
    lang = detect_user_language(profile)
    locale = get_locale(lang)

    # Generate AI summary (in English)
    ai_summary = await get_ai_summary(filtered_items, profile)
    
    # === Final output translation (all at once) ===
    target_language = _extract_user_language(profile)
    if target_language != "English":
        # Translate both items and summary before output
        filtered_items = await translate_content(filtered_items, target_language)
        ai_summary = await translate_text(ai_summary, target_language)

    # Categorize content (after translation)
    categories = await categorize_filtered_content(filtered_items)

    # Build report with clear visual hierarchy
    report_parts = []

    # Header with date and summary
    report_parts.append(f"""{locale["title"]}
{date_str}
{DIVIDER_HEAVY * SEPARATOR_LENGTH}

{ai_summary}
""")

    # Top stories (separate from quota)
    top_stories = categories.pop("top_stories", [])
    if top_stories:
        report_parts.append(format_top_stories(top_stories, lang))
        report_parts.append(DIVIDER_LIGHT * SEPARATOR_LENGTH)
        report_parts.append("")

    # Dynamic allocation for other categories
    # Total quota for non-top-stories items
    total_quota = MAX_DIGEST_ITEMS
    
    # Get categories with items
    active_categories = {k: v for k, v in categories.items() if v}
    
    if active_categories:
        # Calculate total items across all categories
        total_items = sum(len(items) for items in active_categories.values())
        
        # Allocate proportionally, with minimum 1 per category
        category_limits = {}
        remaining_quota = total_quota
        
        for category, items in active_categories.items():
            if total_items > 0:
                # Proportional allocation
                proportion = len(items) / total_items
                allocated = max(1, int(proportion * total_quota))
                # Don't allocate more than available items
                category_limits[category] = min(allocated, len(items))
            else:
                category_limits[category] = len(items)
        
        # Adjust if over quota
        while sum(category_limits.values()) > total_quota:
            # Reduce from largest category
            largest = max(category_limits, key=category_limits.get)
            if category_limits[largest] > 1:
                category_limits[largest] -= 1
            else:
                break
        
        # Render categories with dynamic limits
        for category, items in active_categories.items():
            max_items = category_limits.get(category, len(items))
            report_parts.append(format_category_section(category, items, lang, max_items))

    # Divider before metrics
    report_parts.append(DIVIDER_LIGHT * SEPARATOR_LENGTH)
    report_parts.append("")

    # Metrics
    report_parts.append(format_metrics_section(
        sources_count=sources_count,
        raw_count=raw_count,
        selected_count=len(filtered_items),
        lang=lang
    ))

    # Footer with feedback prompt
    report_parts.append(DIVIDER_HEAVY * SEPARATOR_LENGTH)
    report_parts.append("")
    report_parts.append(locale["helpful_prompt"])

    return "\n".join(report_parts)


def split_report_for_telegram(report: str, max_length: int = 4000) -> List[str]:
    """
    Split a long report into multiple messages for Telegram.

    Telegram has a 4096 character limit per message.

    Args:
        report: Full report text
        max_length: Maximum characters per message

    Returns:
        List of message strings
    """
    if len(report) <= max_length:
        return [report]

    messages = []
    current_message = ""

    # Split by sections (double newlines)
    sections = report.split("\n\n")

    for section in sections:
        if len(current_message) + len(section) + 2 <= max_length:
            if current_message:
                current_message += "\n\n"
            current_message += section
        else:
            if current_message:
                messages.append(current_message)
            current_message = section

    if current_message:
        messages.append(current_message)

    return messages


def format_single_item(item: Dict[str, Any], index: int, lang: str = "zh") -> str:
    """
    Format a single news item for individual message with feedback buttons.

    New format:
    ğŸ”´ 1. Title (clickable)
    Summary text...
    ğŸ’¡ Recommendation reason
    Source: @author

    Args:
        item: Content item dict
        index: Item index number
        lang: Language code

    Returns:
        Formatted message string
    """
    locale = get_locale(lang)
    
    title = item.get("title", "Untitled")
    summary = item.get("summary", "")
    link = item.get("link", "")
    reason = item.get("reason", "")
    source = item.get("source", "")
    author = item.get("author", "")  # Twitter author if available
    section = item.get("section", "other")

    # Priority indicator based on section
    if section == "must_read":
        priority = "ğŸ”´"
    elif section == "macro_insights":
        priority = "ğŸŸ "
    else:
        priority = "ğŸ”µ"

    # Escape HTML special characters to prevent format breaking
    title_escaped = html.escape(title)
    summary_escaped = html.escape(summary) if summary else ""
    reason_escaped = html.escape(reason) if reason else ""

    # Make title clickable if link exists
    if link:
        link_escaped = html.escape(link, quote=True)
        title_html = f'<a href="{link_escaped}">{title_escaped}</a>'
    else:
        title_html = title_escaped

    lines = [f"{priority} <b>{index}. {title_html}</b>"]

    # Add summary if present and not duplicate of title
    if summary_escaped and summary_escaped.strip() != title_escaped.strip():
        lines.append(f"{summary_escaped}")

    # Add recommendation reason (user-centric explanation)
    if reason_escaped:
        reason_prefix = locale.get("reason_prefix", "ğŸ’¡ ")
        lines.append(f"{reason_prefix}{reason_escaped}")

    # Note: Source line removed per user feedback - considered redundant

    return "\n".join(lines)


def generate_summary_header(
    date_str: str,
    ai_summary: str,
    sources_count: int,
    raw_count: int,
    selected_count: int,
    lang: str = "zh"
) -> str:
    """
    Generate the summary header message (without individual items).

    Args:
        date_str: Date string
        ai_summary: AI-generated summary
        sources_count: Number of sources
        raw_count: Raw items count
        selected_count: Selected items count
        lang: Language code

    Returns:
        Formatted header message
    """
    locale = get_locale(lang)
    filter_rate = f"{(selected_count / raw_count * 100):.0f}%" if raw_count > 0 else "N/A"

    return f"""<b>{locale["title"]}</b>
{date_str}
{DIVIDER_HEAVY * SEPARATOR_LENGTH}

{ai_summary}

{DIVIDER_LIGHT * SEPARATOR_LENGTH}

<b>{locale["stats"]}</b>
  {locale["sources"]}: {sources_count}
  {locale["scanned"]}: {raw_count}
  {locale["selected"]}: {selected_count} ({filter_rate})

{DIVIDER_HEAVY * SEPARATOR_LENGTH}
"""


def prepare_digest_messages(
    filtered_items: List[Dict[str, Any]],
    ai_summary: str,
    sources_count: int,
    raw_count: int,
    lang: str = "zh"
) -> tuple:
    """
    Prepare digest as separate messages: header + individual items with hierarchy.

    Items are grouped by section: must_read, recommended, other.

    Args:
        filtered_items: List of filtered content items with 'section' field
        ai_summary: AI-generated summary
        sources_count: Number of sources
        raw_count: Raw items count
        lang: Language code

    Returns:
        Tuple of (header_message, list of (item_message, item_id) tuples)
    """
    date_str = datetime.now().strftime("%Y-%m-%d")
    locale = get_locale(lang)
    category_names = get_category_names(lang)

    # Group items by section (4 categories now)
    must_read = [item for item in filtered_items if item.get("section") == "must_read"]
    macro_insights = [item for item in filtered_items if item.get("section") == "macro_insights"]
    recommended = [item for item in filtered_items if item.get("section") == "recommended"]
    other = [item for item in filtered_items if item.get("section") == "other"]

    # Fallback for legacy format (importance-based)
    if not must_read and not macro_insights and not recommended and not other:
        must_read = [item for item in filtered_items if item.get("importance") == "high"]
        other = [item for item in filtered_items if item.get("importance") != "high"]

    # Generate header with stats
    filter_rate = f"{(len(filtered_items) / raw_count * 100):.0f}%" if raw_count > 0 else "N/A"

    header = f"""<b>{locale["title"]}</b>
{date_str}
{DIVIDER_HEAVY * SEPARATOR_LENGTH}

{ai_summary}

{DIVIDER_LIGHT * SEPARATOR_LENGTH}

<b>{locale["stats"]}</b>
  {locale["sources"]}: {sources_count}
  {locale["scanned"]}: {raw_count}
  {locale["selected"]}: {len(filtered_items)} ({filter_rate})

{DIVIDER_HEAVY * SEPARATOR_LENGTH}
"""

    # Generate individual item messages with hierarchy
    item_messages = []
    item_index = 1

    # Section 1: Must Read (ä»Šæ—¥å¿…çœ‹) - Major events regardless of user preference
    if must_read:
        section_name = category_names.get("must_read", "MUST READ")
        section_header = f"\n<b>{DIVIDER_LIGHT * 8} {section_name} {DIVIDER_LIGHT * 8}</b>\n"
        item_messages.append((section_header, "section_must_read"))

        for item in must_read:
            msg = format_single_item(item, item_index, lang)
            item_id = item.get("id", f"item_{item_index}")
            item_messages.append((msg, item_id))
            item_index += 1

    # Section 2: Macro Insights (è¡Œä¸šå¤§å±€) - Industry context, implicit needs
    if macro_insights:
        section_name = category_names.get("macro_insights", "Industry Context")
        section_header = f"\n<b>{DIVIDER_LIGHT * 8} {section_name} {DIVIDER_LIGHT * 8}</b>\n"
        item_messages.append((section_header, "section_macro_insights"))

        for item in macro_insights:
            msg = format_single_item(item, item_index, lang)
            item_id = item.get("id", f"item_{item_index}")
            item_messages.append((msg, item_id))
            item_index += 1

    # Section 3: Recommended (æ¨è) - Matching user preferences
    if recommended:
        section_name = category_names.get("recommended", "Recommended")
        section_header = f"\n<b>{DIVIDER_LIGHT * 8} {section_name} {DIVIDER_LIGHT * 8}</b>\n"
        item_messages.append((section_header, "section_recommended"))

        for item in recommended:
            msg = format_single_item(item, item_index, lang)
            item_id = item.get("id", f"item_{item_index}")
            item_messages.append((msg, item_id))
            item_index += 1

    # Section 4: Other (å…¶ä»–)
    if other:
        section_name = category_names.get("other", "Other")
        section_header = f"\n<b>{DIVIDER_LIGHT * 8} {section_name} {DIVIDER_LIGHT * 8}</b>\n"
        item_messages.append((section_header, "section_other"))

        for item in other:
            msg = format_single_item(item, item_index, lang)
            item_id = item.get("id", f"item_{item_index}")
            item_messages.append((msg, item_id))
            item_index += 1

    return header, item_messages


def generate_empty_report(lang: str = "zh") -> str:
    """Generate a report when no content is available."""
    date_str = datetime.now().strftime("%Y-%m-%d")
    locale = get_locale(lang)

    return f"""{locale["title"]}
{date_str}
{DIVIDER_HEAVY * SEPARATOR_LENGTH}

{locale["no_content"]}

{locale["possible_reasons"]}
  â€¢ {locale["reason_1"]}
  â€¢ {locale["reason_2"]}
  â€¢ {locale["reason_3"]}

{locale["check_tomorrow"]}

{DIVIDER_LIGHT * SEPARATOR_LENGTH}

{locale["tip"]}
"""


def generate_preview_report(items: List[Dict[str, Any]], lang: str = "zh") -> str:
    """
    Generate a preview/sample report for new users.

    Args:
        items: Sample content items
        lang: Language code

    Returns:
        Formatted preview report
    """
    date_str = datetime.now().strftime("%Y-%m-%d")
    locale = get_locale(lang)
    category_names = get_category_names(lang)

    lines = [
        f"ã€{locale['sample_preview']}ã€‘",
        date_str,
        DIVIDER_HEAVY * SEPARATOR_LENGTH,
        "",
        locale["preview_desc"],
        "",
        DIVIDER_LIGHT * SEPARATOR_LENGTH,
        "",
        f"â–{category_names['must_read']}",
        ""
    ]

    # Sample must-read items
    must_read_samples = [
        "ETH çªç ´ $5000ï¼Œåˆ›å†å²æ–°é«˜" if lang == "zh" else "ETH breaks $5000, new ATH",
        "SEC æ‰¹å‡†ç°è´§ä»¥å¤ªåŠ ETF" if lang == "zh" else "SEC approves spot ETH ETF",
    ]
    for i, title in enumerate(must_read_samples, 1):
        lines.append(f"  {i}. {title}")
    lines.append("")

    lines.extend([
        DIVIDER_LIGHT * SEPARATOR_LENGTH,
        "",
        f"â–{category_names['recommended']}",
        ""
    ])

    # Sample recommended items
    recommended_samples = [
        "Uniswap V4 å‘å¸ƒæ–°æ²»ç†ææ¡ˆ" if lang == "zh" else "Uniswap V4 governance proposal",
        "Arbitrum ç”Ÿæ€ TVL çªç ´ 200 äº¿" if lang == "zh" else "Arbitrum TVL exceeds $20B",
        "æ–° DeFi åè®®èèµ„ 5000 ä¸‡ç¾å…ƒ" if lang == "zh" else "New DeFi protocol raises $50M",
    ]
    for i, title in enumerate(recommended_samples, len(must_read_samples) + 1):
        lines.append(f"  {i}. {title}")
    lines.append("")

    lines.extend([
        DIVIDER_LIGHT * SEPARATOR_LENGTH,
        "",
        f"â–{category_names['other']}",
        ""
    ])

    # Sample other items
    other_samples = [
        "Polygon å‘å¸ƒå¼€å‘è€…å·¥å…·æ›´æ–°" if lang == "zh" else "Polygon developer tools update",
        "Chainlink æ–°å¢æ•°æ®å–‚ä»·" if lang == "zh" else "Chainlink adds new price feeds",
    ]
    total_prev = len(must_read_samples) + len(recommended_samples)
    for i, title in enumerate(other_samples, total_prev + 1):
        lines.append(f"  {i}. {title}")
    lines.append("")

    lines.extend([
        DIVIDER_LIGHT * SEPARATOR_LENGTH,
        "",
        f"{locale['stats']}",
        f"  {locale['sources']}      10",
        f"  {locale['scanned']}      150",
        f"  {locale['selected']}     20 (13%)",
        f"  {locale['time_saved']}   ~2h",
        "",
        DIVIDER_HEAVY * SEPARATOR_LENGTH,
        "",
        locale["preview_footer"]
    ])

    return "\n".join(lines)
